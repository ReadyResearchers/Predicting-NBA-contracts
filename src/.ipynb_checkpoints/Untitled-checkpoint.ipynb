{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e0a9737-b236-4528-935c-d4dd4169c016",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1962914034.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[66], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    test_indices = [:-259]\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data into a pandas DataFrame\n",
    "train = pd.read_csv(\"data/Train_data.csv\")\n",
    "test = pd.read_csv(\"data/Train_data.csv\")\n",
    "# Extract two specific columns\n",
    "features = train.loc[:, [\"VORP_0\", \"Age\"]]\n",
    "target = test.loc[:, \"VORP_0\"]\n",
    "\n",
    "test_indices = [:-259]\n",
    "train_df = df.drop(df.index[test_indices])\n",
    "test_df = df.loc[test_indices]\n",
    "\n",
    "# Extract specific rows\n",
    "mask = (data[\"VORP_0\"] > 0) & (data[\"Age\"] > 0)\n",
    "features = features[mask]\n",
    "target = target[mask]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#train_features, test_features, train_target, test_target = train_test_split(features, target, test_size = :-259)\n",
    "\n",
    "X_train, X_test = train_df.drop('VORP_0', axis=1), test_df.drop('VORP_0', axis=1)\n",
    "y_train, y_test = train_df['VORP_0'], test_df['VORP_0']\n",
    "\n",
    "# Train the model\n",
    "reg = LinearRegression().fit(train_features, train_target)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = reg.predict(test_features)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"R^2:\", reg.score(test_features, test_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f92a7fd-1652-417d-9ec5-486441919e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataframe\n",
    "df = pd.read_csv('data/SPOTRAC.csv')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Locate missing values in the target column\n",
    "missing_values = np.where(np.isnan(df['VORP_0']))\n",
    "\n",
    "# Print the location of missing values\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bef33a47-cdcd-422c-ad0d-6fcbdd5ee69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64),)\n",
      "False\n",
      "False\n",
      "Empty DataFrame\n",
      "Columns: [Player_number, Age, Years, Value, Ave_Salary, Max Value, Year, Year_1, Year _2]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [122, 259]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m predictions \u001b[38;5;241m=\u001b[39m reg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR^2:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/base.py:693\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[1;32m    692\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m--> 693\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mr2_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:911\u001b[0m, in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mr2_score\u001b[39m(\n\u001b[1;32m    785\u001b[0m     y_true,\n\u001b[1;32m    786\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m     force_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    791\u001b[0m ):\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;124;03m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[1;32m    793\u001b[0m \n\u001b[1;32m    794\u001b[0m \u001b[38;5;124;03m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    -inf\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    914\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/metrics/_regression.py:100\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    102\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [122, 259]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('data/SPOTRAC.csv')\n",
    "\n",
    "# Locate missing values in the target column\n",
    "missing_values = np.where(np.isnan(df['VORP_0']))\n",
    "\n",
    "# Print the location of missing values\n",
    "print(missing_values)\n",
    "\n",
    "print(np.isnan(y_test).any())\n",
    "print(np.isnan(X_test).any().any())\n",
    "# Identify the rows with missing values in X_test\n",
    "missing_rows = X_test[X_test.isnull().any(axis=1)]\n",
    "print(missing_rows)\n",
    "\n",
    "# Define the first 259 rows as the test set\n",
    "n = 259\n",
    "test_df = df.iloc[:n]\n",
    "\n",
    "# Define the remaining rows as the training set\n",
    "train_df = df.iloc[n:]\n",
    "\n",
    "# Split the data into features and target variables\n",
    "# Split the data into features and target variables\n",
    "X_train = train_df.drop(columns=['VORP_0'])\n",
    "y_train = train_df['VORP_0']\n",
    "X_test = test_df.drop(columns=['VORP_0'])\n",
    "y_test = test_df['VORP_0']\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"R^2:\", reg.score(X_test, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "864b9cbe-691b-4209-b7cd-6dfaeca7424c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "R^2: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('data/SPOTRAC.csv')\n",
    "\n",
    "# Split the data into features and target variables\n",
    "X = df.drop(columns=['VORP_0'])\n",
    "y = df['Ave_Salary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print(reg)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"R^2:\", reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e9366ce-653b-4954-99ed-222fd763a4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.987503555784828\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('data/SPOTRAC.csv')\n",
    "\n",
    "# Define the first 259 rows as the test set\n",
    "n = 259\n",
    "test_df = df.iloc[:n]\n",
    "\n",
    "# Define the remaining rows as the training set\n",
    "train_df = df.iloc[n:]\n",
    "\n",
    "# Split the data into features and target variables\n",
    "X_train = train_df.drop(columns=['VORP_0', 'Age'])\n",
    "y_train = train_df['Ave_Salary']\n",
    "X_test = test_df.drop(columns=['VORP_0', 'Age'])\n",
    "y_test = test_df['Ave_Salary']\n",
    "\n",
    "# Train the random forest model\n",
    "reg = RandomForestRegressor().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(\"R^2:\", reg.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1d69ce7-0eb0-4087-94aa-34e4fedff409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.9840750477018662\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('data/SPOTRAC.csv')\n",
    "\n",
    "# Define the first 259 rows as the test set\n",
    "n = 259\n",
    "test_df = df.iloc[:n]\n",
    "\n",
    "# Define the remaining rows as the training set\n",
    "train_df = df.iloc[n:]\n",
    "\n",
    "# Split the data into features and target variables\n",
    "X_train = train_df.drop(columns=['VORP_0', 'Age'])\n",
    "y_train = train_df['Ave_Salary']\n",
    "X_test = test_df.drop(columns=['VORP_0', 'Age'])\n",
    "y_test = test_df['Ave_Salary']\n",
    "# Train the Gradient Boosting model\n",
    "gb = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = gb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"R^2:\", gb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "017cab3c-e180-415b-a085-7164051a1fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('data/VORP_Salary.csv')\n",
    "\n",
    "# Define the first 259 rows as the test set\n",
    "n = 259\n",
    "test_df = df.iloc[:n]\n",
    "\n",
    "# Define the remaining rows as the training set\n",
    "train_df = df.iloc[n:]\n",
    "\n",
    "# Split the data into features and target variables\n",
    "X_train = train_df.drop(columns=['VORP_0', 'Age'])\n",
    "y_train = train_df['Ave Salary']\n",
    "X_test = test_df.drop(columns=['VORP_0', 'Age'])\n",
    "y_test = test_df['Ave Salary']\n",
    "\n",
    "# Fit the Lasso model\n",
    "reg = Lasso().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"R^2:\", reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6aefb0bc-1113-476f-9f1b-fdb029ee793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: -0.24502810875861436\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('data/SPOTRAC.csv')\n",
    "\n",
    "# Define the first 259 rows as the test set\n",
    "n = 259\n",
    "test_df = df.iloc[:n]\n",
    "\n",
    "# Define the remaining rows as the training set\n",
    "train_df = df.iloc[n:]\n",
    "\n",
    "# Split the data into features and target variables\n",
    "X_train = train_df.drop(columns=['VORP_0', 'Age'])\n",
    "y_train = train_df['Ave_Salary']\n",
    "X_test = test_df.drop(columns=['VORP_0', 'Age'])\n",
    "y_test = test_df['Ave_Salary']\n",
    "\n",
    "# Fit the SVR model to the training data\n",
    "reg = SVR().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"R^2:\", reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee61bad-dca8-4fd7-b5c3-9e4ec2f9332e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R-squared value: 0.4242482402116021\n",
      "Mean Squared Error: 52339492222271.375\n",
      "R^2: 0.49157112865879005\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "df = pd.read_csv('data/VORP_Salary.csv')\n",
    "\n",
    "# Check for missing values in the DataFrame\n",
    "#print(df.isnull().sum())\n",
    "\n",
    "# Drop any rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Split the data into features and target variables\n",
    "X = df[['VORP_0', 'Age']]\n",
    "y = df['Ave Salary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "r_squared_values = []\n",
    "\n",
    "for i in range(10000):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    # fit a linear regression model to the training data\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    # calculate the R-squared value on the testing data and append it to the list\n",
    "    y_pred = model.predict(X_test)\n",
    "    r_squared_values.append(r2_score(y_test, y_pred))\n",
    "\n",
    "# compute the average R-squared value\n",
    "avg_r_squared = np.mean(r_squared_values)\n",
    "\n",
    "print(\"Average R-squared value:\", avg_r_squared)\n",
    "\n",
    "# Train the model on the training data\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = reg.predict(X_test)\n",
    "print(predictions)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, predictions))\n",
    "print(\"R^2:\", r2_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92bdd193-359c-41a4-88a3-751ee6102df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player number         123.0\n",
      "Age                    30.1\n",
      "Ave Salary       44066288.0\n",
      "Year                 2021.0\n",
      "VORP_0                  4.2\n",
      "VORP_1                  5.1\n",
      "VORP                    4.2\n",
      "Name: 122, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "df = pd.read_csv('data/VORP_Salary.csv')\n",
    "print(df.iloc[122])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a77fb3e-c272-43e4-85c7-985bdacbef65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual Ave Salary  Predicted Ave Salary\n",
      "321            7300000            2109102.70\n",
      "156            6184500            6579582.80\n",
      "373            1882867            3592814.62\n",
      "101            1836090            1187370.13\n",
      "206            1742428             371121.16\n",
      "..                 ...                   ...\n",
      "288           12880000           11157853.39\n",
      "162            4374000            6977114.46\n",
      "218            2641691           10513882.96\n",
      "210            2641691             506086.81\n",
      "45             3000000            2287370.76\n",
      "\n",
      "[77 rows x 2 columns]\n",
      "Mean Squared Error: 30765600446217.875\n",
      "R^2: 0.6258762478758716\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "# Set the float format to two decimal places\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "df = pd.read_csv('data/VORP_Salary.csv')\n",
    "\n",
    "# Check for missing values in the DataFrame\n",
    "#print(df.isnull().sum())\n",
    "\n",
    "# Drop any rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define the first 259 rows as the test set\n",
    "n = 122\n",
    "test_df = df.iloc[:n]\n",
    "\n",
    "# Define the remaining rows as the training set\n",
    "train_df = df.iloc[n:]\n",
    "\n",
    "\n",
    "# Split the data into features and target variables\n",
    "X = df[['VORP_0', 'Age']]\n",
    "y = df['Ave Salary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "r_squared_values = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 122)\n",
    "# fit a linear regression model to the training data\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "                               \n",
    "\n",
    "# Train the model on the training data\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = reg.predict(X_test)\n",
    "#print(predictions)\n",
    "#print(X_train)\n",
    "# Compare the predictions with the actual values from the CSV file\n",
    "test_df = pd.DataFrame({'Actual Ave Salary': y_test, 'Predicted Ave Salary': predictions})\n",
    "print(test_df)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, predictions))\n",
    "print(\"R^2:\", r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78f4132a-d15f-4363-85b3-af5516b25937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gspread in /usr/local/lib/python3.10/site-packages (5.7.2)\n",
      "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.10/site-packages (from gspread) (2.16.2)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.10/site-packages (from gspread) (1.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from google-auth>=1.12.0->gspread) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/site-packages (from google-auth>=1.12.0->gspread) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/site-packages (from google-auth>=1.12.0->gspread) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/site-packages (from google-auth>=1.12.0->gspread) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/site-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2022.12.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e12a5a2-0af2-404d-871c-4b7a01c2a45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting oauth2client\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m874.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/site-packages (from oauth2client) (4.9)\n",
      "Collecting httplib2>=0.9.1\n",
      "  Downloading httplib2-0.21.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.8/96.8 kB\u001b[0m \u001b[31m872.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.10/site-packages (from oauth2client) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/site-packages (from oauth2client) (0.2.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/site-packages (from oauth2client) (0.4.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/site-packages (from httplib2>=0.9.1->oauth2client) (3.0.9)\n",
      "Installing collected packages: httplib2, oauth2client\n",
      "Successfully installed httplib2-0.21.0 oauth2client-4.1.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install oauth2client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a50da5d-3db2-437e-bdb8-d762723ec699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m871.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting et-xmlfile\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f71a6719-8ed1-4734-8531-09e63ece5fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame has been exported to Pred_actual.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data from the CSV file\n",
    "df = pd.read_csv('data/VORP_Salary.csv')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Split the data into features and target variables\n",
    "X = df[['VORP_0', 'Age']]\n",
    "y = df['Ave Salary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_mask = df['Year'] != 2022\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_test, y_test = X[~train_mask], y[~train_mask]\n",
    "\n",
    "# Fit a linear regression model to the training data\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = reg.predict(X_test)\n",
    "\n",
    "# Create a DataFrame with the actual and predicted values\n",
    "test_df = pd.DataFrame({'Actual Ave Salary': y_test, 'Predicted Ave Salary': predictions})\n",
    "\n",
    "# Load the player_number column from the CSV file\n",
    "player_numbers = pd.read_csv('data/VORP_Salary.csv', usecols=['Player number'])\n",
    "\n",
    "# Add the player_number column to the test_df DataFrame\n",
    "test_df['Player number'] = player_numbers.iloc[X_test.index]['Player number'].tolist()\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "excel_file = 'Pred_actual.xlsx'\n",
    "test_df.to_excel(excel_file, index=False)\n",
    "\n",
    "print(f'The DataFrame has been exported to {excel_file}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04656a74-6e41-4b92-8b32-467fa2c45527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77113443-da4b-4818-91b9-1df936a9748c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2459478043.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 26\u001b[0;36m\u001b[0m\n\u001b[0;31m    model = LinearRegression().fit(X_train, y_train)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('data/VORP_Salary.csv')\n",
    "\n",
    "# Define the first 259 rows as the test set\n",
    "n = 122\n",
    "test_df = df.iloc[:n]\n",
    "\n",
    "# Define the remaining rows as the training set\n",
    "train_df = df.iloc[n:]\n",
    "\n",
    "# Split the data into features and target variables\n",
    "X_train = train_df.drop(columns=['VORP_0', 'Age'])\n",
    "y_train = train_df['Ave Salary']\n",
    "X_test = test_df.drop(columns=['VORP_0', 'Age'])\n",
    "y_test = test_df['Ave Salary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# fit a linear regression model to the training data\n",
    " model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Fit the OLS model on the training data\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model using the mean squared error and R^2\n",
    "mse = metrics.mean_squared_error(y_test, predictions)\n",
    "r2 = metrics.r2_score(y_test, predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e1e0bb-a01f-4159-a4f0-d9a70b09115c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: -0.17393009515680125\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('data/VORP_Salary.csv')\n",
    "\n",
    "# Define the target variable\n",
    "y = df['Ave Salary']\n",
    "\n",
    "# Define the features\n",
    "X = df.drop(columns=['VORP_0', 'Age'])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the SVR model to the training data\n",
    "reg = SVR().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"R^2:\", reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4706359b-2111-4683-a8ca-93919ea904e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.660080601616595e-28\n",
      "R^2: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/VORP_Salary.csv')\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(columns=['Ave Salary'])\n",
    "y = df[['VORP_0', 'Age']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "predictions = reg.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, predictions))\n",
    "print(\"R^2:\", r2_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "972c5c32-2123-47c5-a0dc-daff5c5066c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3.957337929572091e-18\n",
      "R^2: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('data/VORP_Salary.csv')\n",
    "\n",
    "# Define the first 259 rows as the test set\n",
    "n = 122\n",
    "test_df = df.iloc[:n]\n",
    "\n",
    "# Define the remaining rows as the training set\n",
    "train_df = df.iloc[n:]\n",
    "\n",
    "# Split the data into features and target variables\n",
    "X_train = train_df.drop(columns=['VORP_0', 'Age'])\n",
    "y_train = train_df['Ave Salary']\n",
    "X_test = test_df.drop(columns=['VORP_0', 'Age'])\n",
    "y_test = test_df['Ave Salary']\n",
    "\n",
    "# Fit the OLS model on the training data\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model using the mean squared error and R^2\n",
    "mse = metrics.mean_squared_error(y_test, predictions)\n",
    "r2 = metrics.r2_score(y_test, predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1731a22-6ca3-417c-9ab1-32d0ed52dcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.06076529360001e-17\n",
      "R^2: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('data/SPOTRAC.csv')\n",
    "\n",
    "# Split the data into features and target variables\n",
    "X_train = train_df.drop(columns=['VORP_0', 'Age'])\n",
    "y_train = train_df['Ave_Salary']\n",
    "X_test = test_df.drop(columns=['VORP_0', 'Age'])\n",
    "y_test = test_df['Ave_Salary']\n",
    "\n",
    "# Fit the model using OLS regression\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = reg.predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y, predictions))\n",
    "print(\"R^2:\", reg.score(X, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
